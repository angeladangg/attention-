# Attention!
A PyTorch project for measuring and pruning redundant attention heads in a Vision Transformer on CIFAR‑10 using cosine similarity, with scripts for analysis, pruning, and fine‑tuning.
